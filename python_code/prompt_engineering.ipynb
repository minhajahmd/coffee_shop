{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()       # load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client, model_name, messages, temperature=0):\n",
    "    input_messages = []     # Store conversation history\n",
    "    # Copy user messages to input_messages in the required format\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "    # Send a request to the model to generate a response\n",
    "    response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=input_messages,\n",
    "    # Temperature controls the creativity of the response\n",
    "    # Lower values give more predictable answers, higher values give more creative answers\n",
    "    temperature=temperature,  # 0.0 = factual, no randomness\n",
    "\n",
    "    # top_p controls the diversity of responses. It looks at the most probable tokens\n",
    "    # Lower values make the response more focused, higher values allow more randomness\n",
    "    top_p=0.8,  # 0.8 = consider 80% of the most probable tokens for the response\n",
    "\n",
    "    # max_tokens limits how long the modelâ€™s response can be\n",
    "    # 2000 tokens is a large number, allowing long responses\n",
    "    max_tokens=2000,  # Maximum length of the model's response (in tokens)\n",
    "    ).choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"RUNPOD_TOKEN\"),\n",
    "    base_url=os.getenv(\"RUNPOD_CHATBOT_URL\"),   #URL for the llama model deployed on runpod\n",
    ")\n",
    "model_name = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the capital of Spain?\"}]\n",
    "response = get_chatbot_response(client, model_name, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Spain is Madrid.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Spain\",\n",
      "    \"capital\": \"Madrid\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions about capitals of countries.\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. Your are not allowed to write anything other than the json object:\n",
    "[\n",
    "{\n",
    "    \"country\": the country that you will get the capital of,\n",
    "    \"capital\": the capital of the country stated,\n",
    "}\n",
    "]\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the capital of Spain?\"})\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Spain', 'capital': 'Madrid'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 'Madrid')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_response[0]), json_response[0]['capital']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"country\": \"Italy\",\n",
      "        \"capital\": \"Rome\"\n",
      "    },\n",
      "    {\n",
      "        \"country\": \"Germany\",\n",
      "        \"capital\": \"Berlin\"\n",
      "    },\n",
      "    {\n",
      "        \"country\": \"Spain\",\n",
      "        \"capital\": \"Madrid\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"\"\"\n",
    "Give me the capital of the following countries: \n",
    "'''\n",
    "1. Italy\n",
    "2. Germany\n",
    "3. Spain\n",
    "'''\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'},\n",
       " {'country': 'Germany', 'capital': 'Berlin'},\n",
       " {'country': 'Spain', 'capital': 'Madrid'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this question: 1+3\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    \"result\": the final number resulted from calulating the question above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113098.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 1345119\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this question: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    \"result\": the final number resulted from calulating the question above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2767979.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 1345119     #Margin of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"steps\": \"First, calculate the division: 259/2 = 129.5. Then, multiply 129.5 by 8654: 129.5 * 8654 = 112,141.5. Next, multiply 91072 by 33: 91072 * 33 = 3,003,336. Now, add 112,141.5 and 3,003,336: 112,141.5 + 3,003,336 = 4,115,477.5. Finally, subtract 12971 from 4,115,477.5: 4,115,477.5 - 12971 = 4,005,706.5.\",\n",
      "    \"result\": 4005706.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this question: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    steps: This is where you solve the equation bit by bit by following the BE DMAS order of operations. You need to show your work and calculate each step leading to the final result. Feel free to write in free text.\n",
    "    result: the final number resulted from calulating the question above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107391.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 4005706.5   #Margin of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.77465628099058"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2767979.0/107391.5      #how much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
